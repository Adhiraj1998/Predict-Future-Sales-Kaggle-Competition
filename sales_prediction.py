# -*- coding: utf-8 -*-
"""Sales Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1evaZt_5D7X8fggfWebxwvByM8A_btl50

# Uploading Files
"""

from google.colab import files
uploaded=files.upload()

uploaded1=files.upload()

uploaded2=files.upload()

uploaded3=files.upload()

uploaded4=files.upload()

uploaded5=files.upload()

"""# Creating the Framework

Here, we generate pandas frameworks for the required csv files that have been uploaded. By doing that, it is easier to access datapoints for analysis and also to view the data in the csv files.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

train_df = pd.read_csv('sales_train_v2.csv')
items_df = pd.read_csv('items.csv')
test_df = pd.read_csv('test.csv')

print(train_df.shape, test_df.shape)

train_df.head()

train_df['date'] = pd.to_datetime(train_df['date'], format='%d.%m.%Y')

dataset = train_df.pivot_table(index=['item_id', 'shop_id'],values=['item_cnt_day'], columns='date_block_num', fill_value=0)

dataset = dataset.reset_index()
dataset.head()

dataset = pd.merge(test_df, dataset, on=['item_id', 'shop_id'], how='left')
dataset = dataset.fillna(0)
dataset.head()

dataset = dataset.drop(['shop_id', 'item_id', 'ID'], axis=1)
dataset.head()

"""Creating the submission framework. After predictions take place by the Deep Learning model (LSTM), predictions shall be stored in the following dataframe, with 2142200 entires."""

X_train = np.expand_dims(dataset.values[:, :-1], axis=2)
y_train = dataset.values[:, -1:]

X_test = np.expand_dims(dataset.values[:, 1:], axis=2)
print(X_train.shape, y_train.shape, X_test.shape)

"""# LSTM Model Creation and Analysis"""

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
model = Sequential()
model.add(LSTM(units=64, input_shape=(33, 1)))
model.add(Dropout(0.3))
model.add(Dense(1))

model.compile(loss='mse',
              optimizer='Nadam',
              metrics=['mean_squared_error'])
model.summary()

history = model.fit(X_train, y_train, batch_size=1024, epochs=10)

plt.plot(history.history['loss'], label= 'loss(mse)')
plt.plot(np.sqrt(history.history['mean_squared_error']), label= 'rmse')
plt.legend(loc=1)

"""The following code is used to make a prediction for the next month after the conclusion of the prevalent dataset (October 2015). The precitions by the LSTM model will generate a csv file with 214200 prediction rows."""

LSTM_prediction = model.predict(X_test)
LSTM_prediction = LSTM_prediction.clip(0, 20)
submission = pd.DataFrame({'ID': test_df['ID'], 'item_cnt_month': LSTM_prediction.ravel()})
submission.to_csv('submission.csv',index=False)

files.download('submission.csv')

"""# Mounting Google Drive in the Virtual Machine

If you are implementing this model on Google Colaboratory, you made need to mount your Google Drive in the runtime's Virtual Machine. I have executed the following code for the ease of usability by other users. 
You may find the following code snippets at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty
"""

from google.colab import drive
drive.mount('/content/drive')

with open('/content/drive/My Drive/foo.txt', 'w') as f:
  f.write('Hello Google Drive!')
!cat /content/drive/My\ Drive/foo.txt

drive.flush_and_unmount()
print('All changes made in this colab session should now be visible in Drive.')